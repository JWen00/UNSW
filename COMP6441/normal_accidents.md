# Normal Accidents
This books preaches the failure of what we consider normal everyday accidents.

This book outlines the failures in which complex systems (not just softwares) in our everyday lives are poorly designed due to our shallow conception of safety and risk.

Perrow discusses the perils and of small accidents which snowball unpredictibly to create a large event with severe consequences.  

The key problems with Perrow identifies have uncanny resemblence to what we have been taught to consider as bad code designed in O-O Design.

1. Complex System
2. Tightly Coupled
3. High Impact (Catatrophic Potential)

## The Black Swan Theory
This theory is actuall extended from an old Latin expression. The latins believed that Black Swans did not exist until it was found later.

The black swan theory refers to unexpected events of large magnitude and consequences  

Key idea; If you never expect something to happen, you don’t prevent it and when it does happen and have a large impact, there are terrible consequences.

## Chernobyl
* Occured on 26th April 1986
* Occured uring a safety test on the reactor
    * Test was a simulation of the electrical power outage to aid the development of a safety procedure for the cooling water circulation   
    * People KNEW that it was a potential safety prolem which cause the nuclear reactor core to overheat
    * The test was delayed for about 10 hours
    * Supervisor didn’t follow the procedure, creating unstable operating systems
    * Along with intentional disabling of reactor safety systems
    * Resulted in the nuclear chain reaction
    * Large amount of energy was suddeny released
    * Vapourised the cooling water
    * Caused a destructive steam explotion
    * Followed by a open-air reactor core fire which released radioactive contamination

So the question is, whose fault is it. One small mistake [TICK] Two small mistakes, three.. four… led to such a disaster.

…the catastrphic accident was caused by gross violations of operating rules and regulations…

Problems:

The plant was not designed to safe

Did not have emergency protection systems capable of preventing the combination of events

Developers considered the combination of events to be impossible

the defiiencies in the reactor designs and operating regulations were set assigned and merely mentioned

Insufficient communiation between safety officer and the operators in chage of the experiment

Control was transferred from the process computer to human operators

Negligence during the contruction of the plant

#### The list goes on and on.. So the question remains - What can we do/take from this?

Design should be tested by multiple people from around the world (as each pair of eyes likes to focus on different things)

The construction must be overseen by people with different interests - not just contruction workers but also engineers who are able to focus on different problems which may potentially arise instead of construction workers just filling in the hole.

NEVER transfer process from computer to human, DISASTER PRONE!